<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Portfolio Fabrice Guibert</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="fabrice-guibert">Fabrice Guibert</h1>
<p><em>E-MAIL: <a href="mailto:fabrice.guibert@epfl.ch">fabrice.guibert@epfl.ch</a><br>
NATIONALITY: FRANCE</em></p>
<h1 id="background">Background</h1>
<p>Iâ€™m a master student in Computer Sciences, studying at EPFL. I have a strong interest in computer graphics, including physically-based rendering and raytracing, although imaging in general is of great interest to me. Having a minor in biocomputing, I enjoy the field quite a lot and am mesmerized by the many applications of computers in areas one would think unrelated at first.<br>
</p>
<h2 id="internships etc">Work Experience</h2>
<p><strong>Spring 2019:</strong></p>
<blockquote>
<p><strong>GTX Medical Eindhoven Internship</strong><br>
 <img src="gtx.png" alt="GTX logo"> <br>
  <br>
<em> GTX Medical aims at accelerating the functional recovery of patients with partial spinal cord injury through
cutting-edge implants. The implant itself needs to be charged wirelessly and safely, to ensure that the device is
able to deliver pulses, while making sure that the system does not overheat when charging. The protocol itself must
therefore guarantee that no overheat can occurr and that it doesn't leave the system in an unsafe or inconsistent state,
regardless of what can happen in the environment. To this end, a theoretical high-level protocol was first proposed.
The technology-specific details were then tackled, to ensure that the approach would be safe and energy-efficient.</em></p>
</blockquote>

<h3 id="project-experience">Project Experience</h3>
<p><strong>Winter 2019:</strong></p>
<blockquote>
<p><strong>Extreme Video Completion</strong><br>
 <video width="800" height="600" controls>
  <source src="cato.mp4" type="video/mp4">
 </video> 
<figcaption>> Reconstructed Video from 1% pixels</figcaption>
  <br>
<em> Master Semester Project
Video completion is a challenging task because one has to ensure not only spatial consistency is achieved, but also temporal consistency to achieve decent perceptual results. In the extreme case where a lot of pixels (that is, 99%) are missing, methods such as inpainting or motion field analysis are no longer available. This project relies upon a novel method, Efficient Filtering by Adaptive Normalization (EFAN), as an attempt to reconstruct videos in an appealing way. By using the filtering of pixels not only spatially but also temporally, it is possible to obtain videos which are perceptually stable, but at the cost of movement faithfullness, relying on a measure of similarity between successive frames to decide the exact amount of temporal blur needed. Relying on this measure, it is possible to perform a preprocessing step on the video, sharing randomly an amount of pixels which depends on the similarity between neighbouring frames. Applying EFAN on the preprocessed frames yield good results, at a complexity which is linear in the number of pixels.</em></p>
</blockquote>

<p><strong>Spring 2018:</strong></p>
<blockquote>
<p><strong>DHHC modelling</strong><br>
 <img src="palmitoylation.png" alt="Example of some structures generated in the project (displayed in VMD)"> <br>
<em> Project in the context of the Biomolecular Structure and Mechanics course.
The proteins from the DHHC family are integral membrane enzymes, of which 23 are responsible for the catalyzation of protein palmitoylation in the human body, otherwise known as posttranslational S-acyltion of cysteines. Crucially, this reaction is reversible, unlike other lipid attachments. A crystal structure for DHHC20 has been solved, and the aim of this project was to use comparative modelling with Modeller and VMD to try and approximate the remaining 22 proteins, assessing the quality of the catalytic sites using DHHC20 as a template.
Membrane-protein assemblies were then formed, to be later used in protein simulations (not done in the scope of this project).</em></p>
</blockquote>
<blockquote>
<p><strong>Nori raytracer</strong><br>
 <img src="env_light_grace-new.png" alt="A sample of what Nori can do"> <br>
<em>Project in the context of the Advanced Computer Graphics course.
The Nori raytracer is an educational raytracer of which the skeleton was provided. The aim of the project was to furnish said skeleton with additional functionality, to create a ray-tracer that would rely on Monte Carlo sampling of light. The basic framework implemented during the semester comprised warping of random samples, BSDFs of plastic, glass, several integrator schemes and multiple-importance sampling. On top, some additional features were added such as textures, displacement maps and image-based lighting were also implemented. The image-based lighting uses a hierarchical scheme to warp random samples efficiently in the scene.</em></p>
</blockquote>
<blockquote>
<p><strong>Super-resolution enhancement</strong><br>
 <img src="super_resolution.png" alt="Super resolution comparison"> <br><br>
<em>Project in collaboration with Aimee Montero and Arsalan Syed in the context of the Computational photography course.<br>
The purpose of this project was to compare two approaches to deep learning based super resolution, one based on wavelet transforms and the other on the spatial domain, to see if by using wavelets, the network could actually learn more information to perform super resolution, and if so try to explain why. Super-resolution has many applications, in biomedical fields, but also simply to improve resolution of images in and on itself. It 		     interestingly relies on aliasing to recover partial information and obtain better resolution. The architecture used was a ten-layers deep. The interpolation used as raw input for the reconstruction contained a lot of noise; interestingly still, wavelets performed better than spatial nets in all cases, although by a rather small margin. </em></p>
</blockquote>
<p><strong>Spring 2017:</strong></p>
<blockquote>
<p><strong>Introduction to Computer Graphics</strong><br>
 <video controls>
  <source src="bezierAndInfiniteTerrain.mp4" type="video/mp4">
 </video> 

<em><br>Project in collaboration with Marc Jolles and Jonathan Scanzi.<br>
The purpose of this project was to construct a 3D scene in realtime, under specific scenery constraints, using OpenGL and C++, ie a rasterizer pipeline. The terrain is procedurally generated (using a variant of Perlin noise), along with special care taken such that said noise is continuous, so as to avoid sudden terrain bumps which would be highly unrealistic. Water was modelled using normal map distortions instead of actual geometry perturbation. Reflection on water is rendered using smart tricks of the framebuffer in the OpenGL pipeline. One can navigate the scene using the keyboard, much like an FPS. The preview uses Bezier curves to move on predetermined paths in a smooth fashion. <br>
God-rays were also added, using an approach suggested in GPU Gems 3, which is basically a ray-tracing approach using far away objects as occluders for the various sources of light in the scene (here specifically, the sun). To speed up computations, only object's contours are considered to create the god-rays, which provide a significant speed-up, as said contours can be downscale, but also discards a lot of potential complexity in the light behaviour. L-systems were also studied, for the purpose of building procedural vegetation.</em></p>
</blockquote>
<p><strong>Spring 2016:</strong></p>
<blockquote>
<p><strong>Introduction to visual Computing</strong><br>
 <img src="visu_comp.png" alt="Moving board in augmented reality"> <br>
<em>Project in collaboration with Marc Jolles and Thomas Garcia.<br>
The goal was to design a game using augmented reality: the user holds a board which can be tilted, so as to move a virtual ball onto the board. The goal is to hit as many objects as possible on the board with the ball to accumulate points!<br>
This project was the occasion to study a simple game-building, study intersections, modelization of simple objects and their bounding boxes from a mathematical perspective, as well as create a simple physical engine, along with some gamification notions, such as scores, visualization and human perception for the purpose of tangible rewards in the context of a game. Basics of real-time image processing, such as Hough transform and filtering were also applied in this project, to detect a real board from a webcam.</em></p>
</blockquote>
</div>
</body>
</html>
